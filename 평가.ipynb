{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": 직관적으로 모델 예측 성능을 나타내는 평가지표\n",
    "   - 이진분류에서 데이터 구성에 따라 성능을 왜곡할 수 있기에 정확도 하나만 사용 x\n",
    "   - 불균형한 레이블 값 분포에서 모델 성능을 평가하기에 적합하지 않음\n",
    "       - ex)레이블 테스트 데이터셋 값이 90%가 1이면 다 1로 예측해도 정확도 0.9 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 생존자 예측에서 여성은 모두 생존으로 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dummy Estimator 만들기\n",
    "    - 남자면 사망, 여자면 생존으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyEstimator(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    # 남자면 사망, 여자면 생존으로 예측\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i]==1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i]=1\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 전처리 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# NULL 처리 함수\n",
    "def fillna(df):\n",
    "    df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
    "    df[\"Cabin\"].fillna('N', inplace=True)\n",
    "    df[\"Embarked\"].fillna('N', inplace=True)\n",
    "    df[\"Fare\"].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 불필요한 칼럼 삭제\n",
    "def drop_features(df):\n",
    "    df.drop([\"Name\",\"Ticket\",\"PassengerId\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 \n",
    "def format_features(df):\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].str[:1]\n",
    "    features = [\"Sex\",\"Cabin\",\"Embarked\"]\n",
    "    for feature in features:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(df[feature])\n",
    "        df[feature] = encoder.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 위 세 함수 한꺼번에 실행\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dummy Estimator로 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는 0.7765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "titanic_df = pd.read_csv(\"titanic_train.csv\")\n",
    "X_titanic_df = titanic_df.drop(\"Survived\",axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "y_titanic_df = titanic_df[\"Survived\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_titanic_df, y_titanic_df, \n",
    "                                                test_size=0.2,random_state=49)\n",
    "\n",
    "myclf = MyDummyEstimator()\n",
    "myclf.fit(X_train,y_train)\n",
    "pred = myclf.predict(X_test)\n",
    "print(\"Dummy Classifier의 정확도는 {0:.4f}\".format(accuracy_score(pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터를 다중분류에서 이진분류로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fake Classifier 만들기\n",
    "    - 모두 0으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X,y):\n",
    "        pass\n",
    "    # 모두 0으로 예측\n",
    "    def predict(self, X):\n",
    "        return np.zeros(X.shape[0], dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- feature, label 데이터셋 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "digits.data의 shape :  (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "digits.target의 shape :  (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "digits = load_digits()\n",
    "print(digits.data)\n",
    "print(\"digits.data의 shape : \",digits.data.shape)\n",
    "print(digits.target)\n",
    "print(\"digits.target의 shape : \",digits.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1797개의 그림들을 8 * 8 해서 64개의 픽셀로 나눴구나 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target==7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fake Classifier로 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "레이브 테스트 세트 0과 1의 분포도\n",
      "0    410\n",
      "1     40\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는 0.9111\n"
     ]
    }
   ],
   "source": [
    "y = (digits.target==7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state = 49)\n",
    "\n",
    "print(\"레이블 테스트 세트 크기 :\",y_test.shape)\n",
    "print(\"레이브 테스트 세트 0과 1의 분포도\")\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "clf = MyFakeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"모든 예측을 0으로 하여도 정확도는 {0:.4f}\".format(accuracy_score(pred,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix (오차행렬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>예측 negative</th>\n",
       "      <th>예측 positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>실제 negative</th>\n",
       "      <td>TN</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>실제 positive</th>\n",
       "      <td>FN</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            예측 negative 예측 positive\n",
       "실제 negative          TN          FP\n",
       "실제 positive          FN          TP"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([[\"TN\",\"FP\"],[\"FN\",\"TP\"]])\n",
    "matrix= pd.DataFrame({\"예측 negative\":[\"TN\",\"FN\"],\"예측 positive\":[\"FP\",\"TP\"]})\n",
    "matrix.index = np.array([\"실제 negative\",\"실제 positive\"])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[410,   0],\n",
       "       [ 40,   0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오차행렬을 통한 정확도 지표의 문제점 인지 \n",
    "    - TP와 FP가 0인 걸로 보아 positive로는 예측을 안했음을 알 수 있다. \n",
    "    - 그럼에도 불균일한 데이터로 인해 정확도가 0.9가 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision(정밀도) & Recall(재현율)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>예측 negative</th>\n",
       "      <th>예측 positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>실제 negative</th>\n",
       "      <td>TN</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>실제 positive</th>\n",
       "      <td>FN</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            예측 negative 예측 positive\n",
       "실제 negative          TN          FP\n",
       "실제 positive          FN          TP"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정밀도 \n",
    "    - 예측을 positive로 한 대상 중에 예측과 실제값이 positive로 일치한 데이터의 비율\n",
    "    - TP / (FP+TP)\n",
    "- 재현율 \n",
    "    - 실제값이 positive인 대상 중에 예측과 실제값이 positive로 일치한 데이터의 비율\n",
    "    - TP / (FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도 : {0:.4f} 0.0\n",
      "재현율 : {0:.4f} 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soyunjung\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"정밀도 : {0:.4f}\".format(precision_score(y_test, pred)))\n",
    "print(\"재현율 : {0:.4f}\".format(recall_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    \n",
    "    print(\"오차 행렬\")\n",
    "    print(confusion)\n",
    "    print(\"정확도 : {0:.4f}, 정밀도 : {1:.4f}, 재현율 : {2:.4f}\"\n",
    "         .format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[97 17]\n",
      " [14 51]]\n",
      "정확도 : 0.8268, 정밀도 : 0.7500, 재현율 : 0.7846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soyunjung\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "titanic_df = pd.read_csv(\"titanic_train.csv\")\n",
    "y_titanic_df = titanic_df[\"Survived\"]\n",
    "X_titanic_df = titanic_df.drop(\"Survived\", axis = 1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \n",
    "                                                   test_size=0.2, random_state=49)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test,lr_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
